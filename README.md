# Arabic NLP Utils ๐ค

<div dir="rtl">

# ููุชุจุฉ ูุนุงูุฌุฉ ุงููุตูุต ุงูุนุฑุจูุฉ ๐ค

ููุชุจุฉ Python ุดุงููุฉ ููุนุงูุฌุฉ ูุชูุธูู ูุชุญููู ุงููุตูุต ุงูุนุฑุจูุฉ.

</div>

## โจ ุงููููุฒุงุช

| ุงูููุฏููู | ุงููุตู |
|----------|-------|
| ๐งน **ุชูุธูู ุงููุตูุต** | ุฅุฒุงูุฉ ุงูุฑูุงุจุทุ ุงูุฅููููุงุชุ ุงูููุดูุงุชุ HTMLุ ุงูุฅูููุฌูุ ุนูุงูุงุช ุงูุชุฑููู |
| ๐ข **ุชุญููู ุงูุฃุฑูุงู** | ุชุญููู ุจูู ุฃุฑูุงู ุนุฑุจูุฉ/ููุฏูุฉ/ุบุฑุจูุฉ + ุชุญููู ุฑูู ููููุงุช |
| โ๏ธ **ุงูุชุดููู** | ุฅุฒุงูุฉ/ูุญุต/ุนุฏ ุงูุญุฑูุงุช ูุงูุชุดููู |
| ๐ฃ๏ธ **ูุดู ุงูููุฌุงุช** | ูุดู ุงูููุฌุฉ (ูุตุฑูุ ุฎููุฌูุ ุดุงููุ ูุบุงุฑุจูุ ุนุฑุงููุ ูุตุญู) |
| ๐ **ุงูุตูุชูุงุช** | ุชุญููู Buckwalter / ูุฑุงููู / IPA |
| ๐ **ุงูุชุทุจูุน** | ุชูุญูุฏ ุงูุฃููุ ุงูุชุงุก ุงููุฑุจูุทุฉุ ุฅุฒุงูุฉ ุงูุชุทููู |
| โ๏ธ **ุงูุชูุทูุน** | ุชูุทูุน ูููุงุช ูุฌูู ูุฃุญุฑู + N-grams |
| ๐ซ **ูููุงุช ุงูุชููู** | ูุงุฆูุฉ ุดุงููุฉ + ุชุตููุฉ ูููุงุช ุงูุชููู |

## ๐ฆ ุงูุชุซุจูุช

```bash
# ูู ุงููุฌูุฏ ุงููุญูู
cd arabic_nlp_utils
pip install -e .

# ุฃู ูุจุงุดุฑุฉ
pip install arabic-nlp-utils
```

## ๐ ุงูุงุณุชุฎุฏุงู ุงูุณุฑูุน

### ุชูุธูู ุงููุตูุต
```python
from arabic_nlp_utils import clean_text

text = "ูุฑุญุจุง   ุจุงูุนุงูู!! @user https://example.com ๐"
result = clean_text(text)
print(result)  # ูุฑุญุจุง ุจุงูุนุงูู
```

### ุฅุฒุงูุฉ ุงูุชุดููู
```python
from arabic_nlp_utils import remove_diacritics, has_diacritics

text = "ุจูุณููู ุงูููููู ุงูุฑููุญููููู ุงูุฑููุญูููู"
print(remove_diacritics(text))  # ุจุณู ุงููู ุงูุฑุญูู ุงูุฑุญูู
print(has_diacritics(text))     # True
```

### ุชุญููู ุงูุฃุฑูุงู
```python
from arabic_nlp_utils import (
    to_western_numerals, to_arabic_numerals,
    number_to_words, extract_numbers
)

print(to_western_numerals("ูกูขูฃ"))     # 123
print(to_arabic_numerals("456"))       # ูคูฅูฆ
print(number_to_words(123))            # ูุฆุฉ ูุซูุงุซุฉ ูุนุดุฑูู
print(extract_numbers("ูุฏู ูขูฃ ูุชุงุจ")) # [23]
```

### ูุดู ุงูููุฌุงุช
```python
from arabic_nlp_utils import detect_dialect

text = "ุงูุง ุนุงูุฒ ุงุฑูุญ ุงูุจูุช ุฏูููุชู ุนุดุงู ุชุนุจุงู ุงูู"
results = detect_dialect(text)
print(results[0]['name_ar'])  # ุงููุตุฑูุฉ
print(results[0]['score'])    # 0.5714
```

### ุงูุตูุชูุงุช
```python
from arabic_nlp_utils import to_buckwalter, to_franco, from_buckwalter

print(to_buckwalter("ุจุณู ุงููู"))  # bsm Allh
print(to_franco("ูุฑุญุจุง"))         # mr7ba
print(from_buckwalter("bsm"))     # ุจุณู
```

### ุงูุชุทุจูุน
```python
from arabic_nlp_utils import normalize

text = "ุฃุญูุฏ ุนูู ุงูุนููุฑุจูุฉ"
print(normalize(text))  # ุงุญูุฏ ุนูู ุงูุนุฑุจูุฉ
```

### ุงูุชูุทูุน
```python
from arabic_nlp_utils import word_tokenize, sentence_tokenize, segment

print(word_tokenize("ูุฑุญุจุง ุจุงูุนุงูู!"))
# ['ูุฑุญุจุง', 'ุจุงูุนุงูู']

print(sentence_tokenize("ูุฑุญุจุง. ููู ุญุงููุ"))
# ['ูุฑุญุจุง', 'ููู ุญุงูู']

print(segment("ูุงููุชุงุจุงุช"))
# {'original': 'ูุงููุชุงุจุงุช', 'prefix': 'ูุงู', 'stem': 'ูุชุงุจ', 'suffix': 'ุงุช'}
```

### ูููุงุช ุงูุชููู
```python
from arabic_nlp_utils import remove_stopwords, is_stopword

text = "ุฃูุง ุฐูุจุช ุฅูู ุงููุฏุฑุณุฉ ูู ุงูุตุจุงุญ"
print(remove_stopwords(text))  # ุฐูุจุช ุงููุฏุฑุณุฉ ุงูุตุจุงุญ
print(is_stopword("ูู"))       # True
```

## ๐ ุฌููุน ุงูุฏูุงู ุงููุชุงุญุฉ

### cleaner.py
- `clean_text()` - ุชูุธูู ุดุงูู
- `remove_urls()` - ุฅุฒุงูุฉ ุงูุฑูุงุจุท
- `remove_emails()` - ุฅุฒุงูุฉ ุงูุฅููููุงุช
- `remove_mentions()` - ุฅุฒุงูุฉ ุงูููุดูุงุช
- `remove_hashtags()` - ุฅุฒุงูุฉ ุงููุงุดุชุงูุงุช
- `remove_html_tags()` - ุฅุฒุงูุฉ HTML
- `remove_extra_spaces()` - ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงูุฒุงุฆุฏุฉ
- `remove_punctuation()` - ุฅุฒุงูุฉ ุงูุชุฑููู
- `remove_non_arabic()` - ุฅุฒุงูุฉ ุบูุฑ ุงูุนุฑุจู
- `remove_emojis()` - ุฅุฒุงูุฉ ุงูุฅูููุฌู
- `reduce_repeated_chars()` - ุชูููู ุงูุชูุฑุงุฑ

### numbers.py
- `to_western_numerals()` - ุชุญููู ูุฃุฑูุงู ุบุฑุจูุฉ
- `to_arabic_numerals()` - ุชุญููู ูุฃุฑูุงู ุนุฑุจูุฉ
- `to_eastern_numerals()` - ุชุญููู ูุฃุฑูุงู ุดุฑููุฉ
- `extract_numbers()` - ุงุณุชุฎุฑุงุฌ ุงูุฃุฑูุงู
- `number_to_words()` - ุฑูู ุฅูู ูููุงุช
- `words_to_number()` - ูููุงุช ุฅูู ุฑูู

### diacritics.py
- `remove_diacritics()` - ุฅุฒุงูุฉ ูู ุงูุชุดููู
- `remove_harakat()` - ุฅุฒุงูุฉ ุงูุญุฑูุงุช ููุท
- `remove_tanween()` - ุฅุฒุงูุฉ ุงูุชูููู
- `remove_shadda()` - ุฅุฒุงูุฉ ุงูุดุฏุฉ
- `has_diacritics()` - ูุญุต ูุฌูุฏ ุชุดููู
- `count_diacritics()` - ุนุฏ ุงูุญุฑูุงุช
- `diacritics_stats()` - ุฅุญุตุงุฆูุงุช ุงูุชุดููู
- `extract_diacritized_words()` - ุงุณุชุฎุฑุงุฌ ุงููููุงุช ุงููุดููุฉ

### dialects.py
- `detect_dialect()` - ูุดู ุงูููุฌุฉ
- `is_dialect()` - ูุญุต ููุฌุฉ ูุนููุฉ
- `get_dialect_words()` - ูููุงุช ุงูููุฌุฉ
- `list_dialects()` - ุงูููุฌุงุช ุงููุฏุนููุฉ

### phonetics.py
- `to_buckwalter()` - ุชุญููู Buckwalter
- `from_buckwalter()` - ุนูุณ Buckwalter
- `to_franco()` - ุชุญููู ูุฑุงููู
- `to_phonetic()` - ุชุญููู ุตูุชู IPA
- `transliterate()` - ูุงุฌูุฉ ููุญุฏุฉ

### normalizer.py
- `normalize()` - ุชุทุจูุน ุดุงูู
- `normalize_alef()` - ุชูุญูุฏ ุงูุฃูู
- `normalize_taa_marbuta()` - ุชุทุจูุน ุงูุชุงุก ุงููุฑุจูุทุฉ
- `normalize_alef_maqsura()` - ุชุทุจูุน ุงูุฃูู ุงูููุตูุฑุฉ
- `normalize_hamza()` - ุชุทุจูุน ุงูููุฒุฉ
- `remove_tatweel()` - ุฅุฒุงูุฉ ุงูุชุทููู

### tokenizer.py
- `word_tokenize()` - ุชูุทูุน ูููุงุช
- `simple_word_tokenize()` - ุชูุทูุน ุจุณูุท
- `sentence_tokenize()` - ุชูุทูุน ุฌูู
- `char_tokenize()` - ุชูุทูุน ุฃุญุฑู
- `remove_prefixes()` - ุฅุฒุงูุฉ ุงูุณูุงุจู
- `remove_suffixes()` - ุฅุฒุงูุฉ ุงูููุงุญู
- `segment()` - ุชุฌุฒุฆุฉ ุงููููุฉ
- `ngrams()` - N-grams ูููุงุช
- `char_ngrams()` - N-grams ุฃุญุฑู

### stopwords.py
- `is_stopword()` - ูุญุต ูููุฉ ุชููู
- `remove_stopwords()` - ุฅุฒุงูุฉ ูููุงุช ุงูุชููู
- `filter_stopwords()` - ุชุตููุฉ ูู ูุงุฆูุฉ
- `get_stopwords()` - ุงูุญุตูู ุนูู ุงููุงุฆูุฉ
- `add_stopwords()` - ุฅุถุงูุฉ ูููุงุช
- `remove_from_stopwords()` - ุญุฐู ูููุงุช
- `stopword_count()` - ุนุฏ ูููุงุช ุงูุชููู
- `stopword_ratio()` - ูุณุจุฉ ูููุงุช ุงูุชููู

## ๐งช ุชุดุบูู ุงูุงุฎุชุจุงุฑุงุช

```bash
cd arabic_nlp_utils
python -m pytest tests/test_all.py -v
```

## ๐ ุงูุฑุฎุตุฉ

MIT License

## ๐ค ุงููุณุงููุฉ

ุงููุณุงููุงุช ูุฑุญุจ ุจูุง! ุงูุชุญ Issue ุฃู Pull Request.
